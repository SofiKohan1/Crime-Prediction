{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data, Datasets & Utils\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pprint\n",
    "import numpy as np\n",
    "from time import time\n",
    "from numpy import log2 as log\n",
    "\n",
    "# Validation methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "# Hyper-parameter optimisation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Feature selection & feature engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import shapiro     # Shapiro Wilk\n",
    "from scipy.stats import normaltest  # D’Agostino’s K^2\n",
    "from scipy.stats import anderson    # Anderson-Darling\n",
    "from scipy.stats import ttest_ind    # independent student t-test; assumes normality\n",
    "from scipy.stats import mannwhitneyu # non-parametric; doesn't assume normality\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plot \n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from collections import Counter\n",
    "import dask.array as da\n",
    "import dask.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data file\n",
    "df_sf = pd.read_csv('Datasets\\Police_Department_Incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncidntNum    0\n",
       "Category      0\n",
       "Descript      0\n",
       "DayOfWeek     0\n",
       "Date          0\n",
       "Time          0\n",
       "PdDistrict    0\n",
       "Resolution    0\n",
       "Address       0\n",
       "X             0\n",
       "Y             0\n",
       "Location      0\n",
       "PdId          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing\n",
    "#handling unique missing value by dropping it\n",
    "df_sf = df_sf.dropna()\n",
    "df_sf.isnull().sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150499 entries, 0 to 150499\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Category    150499 non-null  object \n",
      " 1   Descript    150499 non-null  object \n",
      " 2   DayOfWeek   150499 non-null  object \n",
      " 3   Date        150499 non-null  object \n",
      " 4   Time        150499 non-null  object \n",
      " 5   PdDistrict  150499 non-null  object \n",
      " 6   Resolution  150499 non-null  object \n",
      " 7   Address     150499 non-null  object \n",
      " 8   X           150499 non-null  float64\n",
      " 9   Y           150499 non-null  float64\n",
      " 10  Location    150499 non-null  object \n",
      " 11  PdId        150499 non-null  float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 14.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_coor = df_sf.drop(columns=['IncidntNum'])\n",
    "df_coor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Descript', 'DayOfWeek', 'Date', 'Time', 'PdDistrict',\n",
       "       'Resolution', 'Address', 'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting object values to tranform into int \n",
    "sel = df_coor.select_dtypes(exclude=['float64']).columns \n",
    "sel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding objects\n",
    "encode = defaultdict(preprocessing.LabelEncoder)\n",
    "df_coor[sel] = df_coor[sel].apply(lambda x: encode[x.name].fit_transform(x.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers dropped\n",
    "df_coor.drop(df_sf[df_sf['Y'] == df_sf['Y'].max()].index, inplace=True)\n",
    "df_coor.drop(df_sf[df_sf['X'] == df_sf['X'].max()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_coor[['Category', 'Descript', 'DayOfWeek', 'Date', 'Time',\n",
    "             'Resolution', 'Address', 'X', 'Y', 'Location', 'PdId']]\n",
    "y = df_coor['PdDistrict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "cluster = LocalCluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, rank_metric='score', n_top=3):\n",
    "    \"\"\"\n",
    "    Utility function to report best scores.\n",
    "    :param results: the cv_results_ data structure from the optimisation algorithm\n",
    "    :param rank_metric: name of the metric to report results for\n",
    "    :param n_top: the number of top results to report\n",
    "    \"\"\"\n",
    "    print(\"\\nModels ranked according to\", rank_metric)\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_\" + rank_metric] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.2f} (+/- {1:.2f})\".format(\n",
    "                  results[\"mean_test_\" + rank_metric][candidate],\n",
    "                  results[\"std_test_\" + rank_metric][candidate]*2))\n",
    "            print(\"Params: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> STARTING GRID SEARCH ...\n"
     ]
    }
   ],
   "source": [
    "n_iter_search = 11\n",
    "n_folds = 5\n",
    "\n",
    "# instantiating the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# defining parameter grid\n",
    "param_grid = {\"max_depth\": [2, 4, 6, 8, None],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 6, 8, 10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"splitter\": [\"best\", \"random\"]}\n",
    "\n",
    "# run grid search\n",
    "print(\"\\n> STARTING GRID SEARCH ...\")\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=n_folds)\n",
    "\n",
    "start_time = time()\n",
    "grid_search.fit(X, y)\n",
    "end_time = time()\n",
    "\n",
    "print(type(grid_search))\n",
    "\n",
    "print(\"> GRID SEARCH COMPLETE\")\n",
    "\n",
    "print(\"\\nGridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (end_time - start_time, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# defining parameter grid\n",
    "param_grid = {\"max_depth\": [2, 4, 6, 8, None],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 6, 8, 10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"splitter\": [\"best\", \"random\"]}\n",
    "\n",
    "# defining multiple metrics for scoring\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'prec_macro': make_scorer(precision_score, average='macro', zero_division=0), \n",
    "    'rec_macro': make_scorer(recall_score, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "# run grid search\n",
    "print(\"\\n> STARTING GRID SEARCH ...\")\n",
    "n_folds = 10\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=n_folds, scoring=scoring, refit='prec_macro')\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"> GRID SEARCH COMPLETE\")\n",
    "print(\"\\nGridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "\n",
    "# Get the best model according to each of the 3 metrics used\n",
    "report(grid_search.cv_results_, 'accuracy', n_top=1)\n",
    "report(grid_search.cv_results_, 'prec_macro', n_top=1)\n",
    "report(grid_search.cv_results_, 'rec_macro', n_top=1)\n",
    "\n",
    "try:\n",
    "    print(\"Best score: %0.2f \" % (grid_search.best_score_))\n",
    "except:\n",
    "    print(\"Best score not available (refit set to False presumably)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
